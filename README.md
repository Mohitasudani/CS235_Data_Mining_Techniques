# CS235_Data_Mining_Techniques

We present the findings of our CS235 Winter’23 Default project, a paper where we perform and evaluate classification and clustering models primarily on the Breast Cancer Wisconsin Diagnostic Dataset. We wish to determine which methods are best for classifying- ing malignant and benign tumors and attempt to cluster each type of data into groups of similar features. This paper uses Random Forest, Multi-Layer Perceptron, and K-Nearest Neighbor models for the classification tasks and DBSCAN, Spectral Clustering, and Agglomerative Clustering with Single Linkage for the clustering methods. Our findings show what classification and clustering models could have advantages on datasets similar in nature to the cancer dataset we used in our research.

In this project, we compare different approaches to determine the performances of different classification methods. Classification is a widely used machine learning technique that is used to assign labels to a given input based on prior knowledge[1]. Features and labels from existing information are used with various algorithms to best label unclassified data while ensuring that there is a reasonable amount of confidence to say that the classification is correct. We compare three of the most popular methods here: Random Forest, which classifies each point based upon information gained on a tree-like structure; Multi-Layer Perceptron, which feeds the features into a neural network and outputs weights corresponding to the probability that it’s a certain class; and K-Nearest Neighbors, which uses a distance function to see how far a point is from K-neighbors to classify it.
The performance of each of these clustering methods will be evaluated with the Breast Cancer Wisconsin Diagnostic Dataset. We will then compare the results found from each of the three clustering methods to determine which method performed the best given this spread of data.
We also evaluate how different clustering methods are able to accurately divide data into smaller clusters with related items. Clustering is a machine learning technique that breaks a given dataset into groups, with the goal of having items in the same groups be close to each other[2]. We analyze the following three clustering methods: Spectral Clustering, which is a density-based machine learning model that uses eigenvalues to determine the smallest split of two clusters; DBSCAN, which is also a density-based model that can create non-uniform clusters using a propagation-like technique; and Agglomerative Clustering with Single Linkage, which creates clusters by continuously merging points into clusters using the single linkage criteria.
To demonstrate the correctness of our implementations, we also ran our algorithms on a much smaller dataset. The correctness dataset consists of 17 objects in total, with 2 features each, and we verify the distinguishable inputs using the given class labels.
